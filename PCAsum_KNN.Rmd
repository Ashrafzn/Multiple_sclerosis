---
title: "PCAsum_KNN"
author: "Fabien Bijsterbosch"
date: "2023-11-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning=FALSE}
library(caret)
library(nFactors)
library(EFA.dimensions)
library(stats)
library(factoextra)
library(FactoMineR)
library(ggplot2)
library(patchwork)
library(corrplot)

```



```{r}
#Load in the dataset

sumscores_data <- read.csv("sumscores_output_scaled_lesions_only.csv")
head(sumscores_data, 10)

```


Firstly, we check the correlation of the sumscores. ccording to the literature (James, Witten, Hastie & Tibshirani 2021) Principal Component Analyis(PCA) allows us to summarize a set of highly correlated variables with a smaller number of representative variables.

Furthermore, these representative variables collectively explain most of the variability in the original dataset. The dimension reduction of PCA will then allow us to identify similar groups in a low(er) dimensional space.


```{r}
#Only select the information from the dataset we are interested in. 
# Which are : sumscores of the lipidclasses and the types

sumscores = sumscores_data[, 9:34]
head(sumscores, 10)




```


```{r}
#Correlation matrix.
#cor(sumscores[, 11:33])
corrplot(cor(sumscores[, 3:26]), tl.col = "black")


```


We already see that the sumscores seem to be highly positively correlated with each other, thus our PCA would make sense.

```{r}
pr.out = prcomp(sumscores[, 3:26], scale = TRUE)

```

The goal of PCA is to find a low-dimensional representation of our data that captures as much information, which are captured in the principal components. The following table contains the component loadings compared to our original variables where the loading represents the amount of component variance explained
by the variable (e.g., the “correlation” of the variable with the component).
Again, we see a small slice of the data, which contains the loading of the first five variables of the first four components to get a general idea of the PCA. The total PCA contains the full 33 components


```{r}

pr.out$rotation[,1:5]


```



```{r}

var_explained = 100 * pr.out$sdev**2 / sum(pr.out$sdev**2)

par(mfrow = c(1,2))
plot(cumsum(var_explained), type = "o", ylab = "Cumulative PVE", xlab = "Number of components", col = "brown3")
plot(var_explained, type = "o", ylab = "PVE", xlab = "Number of components", col = "lightblue", xlim = c(0, 10))

```


```{r}
summary(pr.out)

```


```{r}

ev = eigen(cor(sumscores[, 3:26]))
ev$values

```

Both the scree plot and the eigenvalue criterion do agree with each other that the amount of principal components we would need would be three. 


To able to give meaning to these newly derived variables, the loadings will be inspected. It can be inspected by how much "weight" is approximately placed on the orignal variables by the loading vectors.



```{r}

#Getting only the first three principal components
pr.out$rotation[, 1:3]
```
To summarize this table and make it a bit more readable, I do not display certain loadings below a certain threshold, which is 0.2 in this case.

```{r}

rotation_matrix <- pr.out$rotation[, 1:3]  # Assuming you want the first 3 components

# Set the threshold
threshold <- 0.2

# Filter the rotation matrix based on the threshold
filtered_loadings <- round(rotation_matrix, 3)
filtered_loadings[abs(filtered_loadings) < threshold] <- NA  # Replace values below threshold with empty strings

# Display the filtered loadings
rotation_matrix
filtered_loadings


```
We already see that some of the variables can load positive on the first component, whereas some seem to load negative on the first component. The second component seems to be a discrimination component between the variables that loaded low on the first one.

Principal component 1:

- Positive correlations :
PE, PS, PI, LysoPC, LysoPE, LysoPI, NAPE, GPNAE, NAE, DAG, MAG, SM, CER, Cerebroside. 

- Negative correlations
PG...BMP, LysoPS, LysoPG, LysoNAPE, TAG, FFA, Oxylipins, CE.


Principal component 2:
- Positive correlations
LysoPG, LysoNAPE, TAG, Sterols

- Negative correlations
PG...BMP, FFA, LysoNAPE.

Principal component 3:
- Positive correlations
TAG, CE

-Negative correlation
Sterols, LysoPS 


## Interpretation : ? # Ask Daan.

To my own understanding the first principal component seems to be some form of general lipid class, where there is a discrepancy between two types of lipids.

A quick search on the internet found that the lipids that load positive are lipids that are associated with cellular membranes and structural integretity whereas the negative loadings have more to do with energy storage.

For the second component, the difference is not that clear, for this we need more knowledge on the theoretical domain. 
```{r}
fviz_pca_var(pr.out) # Graph of variables

```



```{r}

fviz_pca_ind(pr.out,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind = sumscores$types, # color by groups
                          addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups"
             )

```





